{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2\n",
    "\n",
    "#### Machine Learning in Korea University\n",
    "#### COSE362, Fall 2018\n",
    "#### Due : 11/26 (TUE) 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this assignment, you will learn various classification methods with given datasets.\n",
    "* Implementation detail: Anaconda 5.3 with python 3.7\n",
    "* Use given dataset. Please do not change train / valid / test split.\n",
    "* Use numpy, scikit-learn, and matplotlib library\n",
    "* You don't have to use all imported packages below. (some are optional). <br>\n",
    "Also, you can import additional packages in \"(Option) Other Classifiers\" part. \n",
    "* <b>*DO NOT MODIFY OTHER PARTS OF CODES EXCEPT \"Your Code Here\"*</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression #\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Additional packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your own packages if you need(only in scikit-learn, numpy, pandas).\n",
    "# Your Code Here\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "> 1. Load \"train.csv\". It includes all samples' features and labels.\n",
    "> 2. Training four types of classifiers(logistic regression, decision tree, random forest, support vector machine) and <b>validate</b> it in your own way. <b>(You can't get full credit if you don't conduct validation)</b>\n",
    "> 3. Optionally, if you would train your own classifier(e.g. ensembling or gradient boosting), you can evaluate your own model on the development data. <br>\n",
    "> 4. <b>You should submit your predicted results on test data with the selected classifier in your own manner.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task & dataset description\n",
    "1. 6 Features (1~6)<br>\n",
    "Feature 2, 4, 6 : Real-valued<br>\n",
    "Feature 1, 3, 5 : Categorical <br>\n",
    "\n",
    "2. Samples <br>\n",
    ">In development set : 2,000 samples <br>\n",
    ">In test set : 1,500 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load development dataset\n",
    "Load your development dataset. You should read <b>\"train.csv\"</b>. This is a classification task, and you need to preprocess your data for training your model. <br>\n",
    "> You need to use <b>1-of-K coding scheme</b>, to convert categorical features to one-hot vector. <br>\n",
    "> For example, if there are 3 categorical values, you can convert these features as [1,0,0], [0,1,0], [0,0,1] by 1-of-K coding scheme. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training your model, you need to convert categorical features to one-hot encoding vectors.\n",
    "# Your Code Here\n",
    "train = pd.read_csv('./data/train.csv').values  # Loading data and convert to np.ndarray\n",
    "\n",
    "def one_hot(data):\n",
    "    feature2idx = []\n",
    "    for categorical in [0,2,4]:\n",
    "        f2i = {value : idx for idx, value in enumerate(sorted(set(data[:, categorical])))}\n",
    "        feature2idx.append(f2i)\n",
    "        \n",
    "    new_data = []\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        new_row = []\n",
    "        row_length = len(data[0])\n",
    "        cnt = 0\n",
    "\n",
    "        for j in range(row_length):\n",
    "            if j in [0,2,4]:\n",
    "                convert_each_value = [0 for j in range(len(feature2idx[cnt]))]\n",
    "                convert_each_value[feature2idx[cnt].get(data[i, j])] = 1\n",
    "                new_row.extend(convert_each_value)\n",
    "                cnt += 1\n",
    "            else:\n",
    "                new_row.extend([data[i, j]])\n",
    "        \n",
    "        new_data.append(new_row)\n",
    "                \n",
    "    return np.array(new_data)\n",
    "\n",
    "X_tr = one_hot(train)[:, :-1]\n",
    "Y_tr = one_hot(train)[:, -1]\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Train and validate your <b>logistic regression classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/chanjoo_external/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Volumes/chanjoo_external/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cv error :  0.2895\n",
      "mean f1 score is :  0.26301157027955424\n"
     ]
    }
   ],
   "source": [
    "# Training your logistic regression classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=1)\n",
    "\n",
    "ith_f1_score = []\n",
    "ith_cv_score = []\n",
    "for train_index, valid_index in cv.split(X_tr):\n",
    "    x_train = X_tr[train_index]\n",
    "    x_valid = X_tr[valid_index]\n",
    "    y_train = Y_tr[train_index]\n",
    "    y_valid = Y_tr[valid_index]\n",
    "\n",
    "    model = LogisticRegression(C=10, solver='lbfgs', max_iter=300)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_predict = model.predict(x_valid)\n",
    "    ith_f1_score.append(f1_score(y_valid, y_predict, average='macro').mean())\n",
    "\n",
    "\n",
    "print('mean cv acc : ', cross_val_score(model, X_tr, Y_tr, cv=cv).mean())\n",
    "print('mean f1 score is : ', np.mean(ith_f1_score))\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Train and validate your <b>decision tree classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cv error :  0.438\n",
      "mean f1 score :  0.37187414990073886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/chanjoo_external/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Volumes/chanjoo_external/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Training your decision tree classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=1)\n",
    "\n",
    "ith_f1_score = []\n",
    "\n",
    "for train_index, valid_index in cv.split(X_tr):\n",
    "    x_train = X_tr[train_index]\n",
    "    x_valid = X_tr[valid_index]\n",
    "    y_train = Y_tr[train_index]\n",
    "    y_valid = Y_tr[valid_index]\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=17)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_predict = model.predict(x_valid)\n",
    "    ith_f1_score.append(f1_score(y_valid, y_predict, average='macro'))\n",
    "    \n",
    "print('mean cv acc : ', cross_val_score(model, X_tr, Y_tr, cv=cv).mean())\n",
    "print('mean f1 score : ', np.mean(ith_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Train and validate your <b>random forest classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training your random forest classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=1)\n",
    "\n",
    "num_trees = [100, 300, 500, 1000] # best : 500\n",
    "ith_f1_score = []\n",
    "\n",
    "for num in num_trees:\n",
    "    \n",
    "    for train_index, valid_index in cv.split(X_tr):\n",
    "        x_train = X_tr[train_index]\n",
    "        x_valid = X_tr[valid_index]\n",
    "        y_train = Y_tr[train_index]\n",
    "        y_valid = Y_tr[valid_index]\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=num)\n",
    "        model.fit(x_train, y_train)\n",
    "    \n",
    "        y_predict = model.predict(x_valid)\n",
    "        ith_f1_score.append(f1_score(y_valid, y_predict, average='macro'))\n",
    "\n",
    "    print('mean cv acc : ', cross_val_score(model, X_tr, Y_tr, cv=cv).mean())\n",
    "    print('mean f1 score : ', np.mean(ith_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Train and validate your <b>support vector machine classifier</b>, and print out your validation(or cross-validation) error.\n",
    "> If you want, you can use cross validation, regularization, or feature selection methods. <br>\n",
    "> <b> You should use F1 score('macro' option) as evaluation metric. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training your support vector machine classifier, and print out your validation(or cross-validation) error.\n",
    "# Save your own model\n",
    "# Your Code Here\n",
    "cv = ShuffleSplit(n_splits=5, test_size=1/5, random_state=1)\n",
    "\n",
    "ith_f1_score = []\n",
    "\n",
    "for train_index, valid_index in cv.split(X_tr):\n",
    "    x_train = X_tr[train_index]\n",
    "    x_valid = X_tr[valid_index]\n",
    "    y_train = Y_tr[train_index]\n",
    "    y_valid = Y_tr[valid_index]\n",
    "    \n",
    "    model = SVC(kernel='poly', gamma=0.1, coef0=10)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_predict = model.predict(x_valid)\n",
    "    ith_f1_score.append(f1_score(y_valid, y_predict, average='macro'))\n",
    "    \n",
    "print('mean cv acc : ', cross_val_score(model, X_tr, Y_tr, cv=cv).mean())\n",
    "print('mean f1 score : ', np.mean(ith_f1_score))\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Option) Other Classifiers.\n",
    "Train and validate other classifiers by your own manner.\n",
    "> <b> If you need, you can import other models only in this cell, only in scikit-learn. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need additional packages, import your own packages below.\n",
    "# Your Code Here\n",
    "\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your prediction on the test data.\n",
    "\n",
    "* Select your model and explain it briefly.\n",
    "* You should read <b>\"test.csv\"</b>.\n",
    "* Prerdict your model in array form.\n",
    "* Prediction example <br>\n",
    "[2, 6, 14, 8, $\\cdots$]\n",
    "* We will rank your result by <b>F1 metric(with 'macro' option)</b>.\n",
    "* <b> If you don't submit prediction file or submit it in wrong format, you can't get the point for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain your final model\n",
    "Logistic Regression, Decision Tree, Random Forest, Support Vector Machine의 네가지 모델에 대하여 \n",
    "sklearn 공식 문서를 참고하여 각 모델의 파라미터 값들 중, 수업시간에 배운 파라미터들을 조정해가며 F1 score를 비교한 결과, Random Forest를 선택하였다.(tree 개수 : 500 / 5-fold cross validation 실행, 일반적으로 treed의 개수를 늘릴수록 좋은 결과를 기대할 수 있지만 특정 수 이상부터는 영향이 없다.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset.\n",
    "# Your Code Here\n",
    "test = pd.read_csv('./data/test.csv').values\n",
    "X_te = one_hot(test)[:, :] # 테스트 셋은 target값 포함 안되어있음\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target class\n",
    "# Make variable \"my_answer\", type of array, and fill this array with your class predictions.\n",
    "# Modify file name into your student number and your name.\n",
    "# Your Code Here\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(X_tr, Y_tr)\n",
    "\n",
    "my_answer = model.predict(X_te)\n",
    "\n",
    "file_name = \"HW2_2013190702_이찬주.csv\"\n",
    "# End Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for saving predicted answers. DO NOT MODIFY.\n",
    "pd.Series(my_answer).to_csv(\"./data/\" + file_name, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
